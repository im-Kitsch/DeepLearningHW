{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python CODE\n",
    "import numpy as np\n",
    "# DO NOT FORGET TO SPECIFY THE SAME SEED\n",
    "np.random.seed ( 12345 )\n",
    "def initialize(input_dim, hidden_dim,  output_dim, batch_size):\n",
    "    W1 = np.random.randn ( hidden_dim , input_dim ) * 0.01\n",
    "    b1 = np.zeros ( ( hidden_dim , ) )\n",
    "    W2 = np.random.randn ( hidden_dim , hidden_dim ) * 0.01\n",
    "    b2 = np.zeros ( ( hidden_dim , ) )\n",
    "    W3 = np.random.randn ( output_dim , hidden_dim ) * 0.01\n",
    "    b3 = np.zeros ( ( output_dim , ) )\n",
    "    b1 = np.reshape( b1, ((b1.shape)[0],1)  )\n",
    "    b2 = np.reshape( b2, ((b2.shape)[0],1)  )\n",
    "    b3 = np.reshape( b3, ((b3.shape)[0],1)  )\n",
    "    # list of all  network parameters\n",
    "    parameters = [W1, b1 , W2, b2 , W3, b3 ]\n",
    "    # minibatch of input instances\n",
    "    x = np.random.rand ( input_dim , batch_size )\n",
    "    # ground truths\n",
    "    y = np.random.randn ( output_dim , batch_size )\n",
    "    return parameters , x , y\n",
    "# initialize parameters , inputs and targets\n",
    "parameters, X, Y = initialize ( 3 , 4 , 2 , 5 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## question 01\n",
    "forward pass and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(inX):  \n",
    "    return 1.0/(1+np.exp(-inX))     \n",
    "def f_NN(parameters, x):\n",
    "    [W1, b1, W2, b2, W3, b3] = parameters \n",
    "    o1 = np.dot(W1,x)  + b1\n",
    "    H1 = sigmoid( o1  ) #\n",
    "    o2 = np.dot(W2,H1) + b2\n",
    "    H2 = sigmoid( o2  ) #\n",
    "    o3 = np.dot(W3,H2) + b3\n",
    "    forward = [o1, H1, o2, H2, o3]\n",
    "    return forward\n",
    "def loss( parameters, x, y):\n",
    "    forward = f_NN(parameters, x)\n",
    "    [o1, H1, o2, H2, o3] = forward\n",
    "    guess_y = o3\n",
    "    L = 0\n",
    "    steps = y.shape\n",
    "    steps = steps[1]\n",
    "    for i in range( steps  ):\n",
    "        err = guess_y[:,i] - y[:,i]\n",
    "        L += np.linalg.norm( err ) \n",
    "    return L/(2*steps) , forward\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## question 2\n",
    "backpropagation  \n",
    "dx_dx means partial derivation\n",
    "Xi_ij means $i_{th}$ layer, ij element \\\\\n",
    "for vector xj\n",
    "$$ dL/dxx \\\\   \n",
    "   .../do3 = (o3 -y)^T\\\\\n",
    "   o = Wx+b \\quad given \\quad dL/do \\\\\n",
    "   dL/db = dL/do\\\\\n",
    "       dL/dW = x \\times dL/do \\quad (outer)\\\\\n",
    "       dL/dx = dL/do \\times W  \\\\\n",
    "   h = sig(o) \\quad given\\quad dL/dh \\\\\n",
    "   dL/do = dL/dh \\times (1-h) \\times h \\quad (np.multiply)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Loss, forward = loss( parameters, X, Y)\n",
    "[O1, H1, O2, H2, O3] = forward\n",
    "[W1, b1, W2, b2, W3, b3] = parameters\n",
    "steps = Y.shape\n",
    "steps = steps[1] \n",
    "detW1 = {}\n",
    "detb1 = {}\n",
    "detW2 = {}\n",
    "detb2 = {}\n",
    "detW3 = {}\n",
    "detb3 = {}\n",
    "for i in range (steps):\n",
    "    [o1,h1,o2,h2,o3,x,y] = [ O1[:,i], H1[:,i], O2[:,i], H2[:,i], O3[:,i], X[:,i], Y[:,i] ]\n",
    "    \n",
    "    dL_do3 = o3 - y\n",
    "    \n",
    "    dL_db3 = dL_do3\n",
    "    dL_dW3 = np.outer(h2, dL_do3)\n",
    "    dL_dh2 = np.dot(dL_do3, W3)\n",
    "    dL_do2 = dL_dh2 * (1-h2) * h2\n",
    "    \n",
    "    dL_db2 = dL_do2\n",
    "    dL_dW2 = np.outer(h1, dL_do2)\n",
    "    dL_dh1 = np.dot(dL_do2, W2)\n",
    "    dL_do1 = dL_dh1 * (1-h1) * h1\n",
    "    \n",
    "    dL_db1 = dL_do1\n",
    "    dL_dW1 = np.outer(x, dL_do1)    \n",
    "    if i == 0:\n",
    "        detW1 = dL_dW1\n",
    "        detb1 = dL_db1\n",
    "        detW2 = dL_dW2\n",
    "        detb2 = dL_db2\n",
    "        detW3 = dL_dW3\n",
    "        detb3 = dL_db3              \n",
    "    else:\n",
    "        detW1 += dL_dW1\n",
    "        detb1 += dL_db1\n",
    "        detW2 += dL_dW2\n",
    "        detb2 += dL_db2\n",
    "        detW3 += dL_dW3\n",
    "        detb3 += dL_db3        \n",
    "detW1 /= steps\n",
    "detb1 /= steps\n",
    "detW2 /= steps\n",
    "detb2 /= steps\n",
    "detW3 /= steps\n",
    "detb3 /= steps\n",
    "err = [detW1,detb1,detW2,detb2,detW3,detb3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "gradient checking program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NG_check(parameters, X, Y):\n",
    "    steps = len(parameters)\n",
    "    gradient = []\n",
    "    for index in range(steps):\n",
    "        size = (parameters[index]).shape\n",
    "        gradient.append( ( np.zeros(size) ).T  )\n",
    "        for i, row in enumerate(parameters[index]):\n",
    "            for j, ele in enumerate(row):\n",
    "                temp = parameters[index][i][j]\n",
    "                if temp == 0:\n",
    "                    parameters[index][i][j] = 0.01\n",
    "                    lossA, forward = loss( parameters, X, Y)\n",
    "                    parameters[index][i][j] = 0\n",
    "                    parameters[index][i][j] = -0.01\n",
    "                    lossB, forward = loss( parameters, X, Y)\n",
    "                    parameters[index][i][j] = 0\n",
    "                    gradient[index][j][i] = (lossA - lossB)/(2*0.01)\n",
    "                    \n",
    "                else:\n",
    "                    delta = temp * 0.01\n",
    "                    parameters[index][i][j] += delta\n",
    "                    lossA, forward = loss( parameters, X, Y)\n",
    "                    parameters[index][i][j] = temp\n",
    "                    parameters[index][i][j] -= delta\n",
    "                    lossB, forward = loss( parameters, X, Y)\n",
    "                    parameters[index][i][j] = temp\n",
    "                    gradient[index][j][i] = (lossA - lossB)/(2*delta)\n",
    "    return gradient    \n",
    " \n",
    "gradient = NG_check(parameters, X, Y)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### analytical gradient  \n",
    "the order $\\frac{dL}{d..}$  \n",
    "W1 b1 W2 b2 W3 b3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-3.55164801e-07,  2.02412923e-06,  1.12728984e-05,\n",
       "          6.96166795e-07],\n",
       "        [ 4.19035853e-07,  1.85604158e-06,  8.49377219e-06,\n",
       "          6.27452005e-07],\n",
       "        [ 3.52847230e-06,  1.01560709e-06, -3.51794858e-06,\n",
       "          2.95038713e-07]]),\n",
       " array([6.68064134e-06, 3.46671844e-06, 1.26685662e-06, 1.08561520e-06]),\n",
       " array([[ 3.99898284e-06, -9.83803475e-04,  5.26033041e-04,\n",
       "          6.09661103e-04],\n",
       "        [ 4.14561394e-06, -9.89356662e-04,  5.29099114e-04,\n",
       "          6.13133340e-04],\n",
       "        [ 3.09285858e-06, -9.86819589e-04,  5.26928985e-04,\n",
       "          6.11301153e-04],\n",
       "        [ 1.00056924e-05, -9.82852021e-04,  5.30215253e-04,\n",
       "          6.10570429e-04]]),\n",
       " array([ 6.07123945e-06, -1.96949231e-03,  1.05156448e-03,  1.22000815e-03]),\n",
       " array([[-0.29601562, -0.00063616],\n",
       "        [-0.29315414, -0.00062495],\n",
       "        [-0.29558964, -0.00062947],\n",
       "        [-0.29427093, -0.00063094]]),\n",
       " array([-0.58798803, -0.00125797])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### numerical gradient\n",
    "the order is the same as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[4.19325363e-07, 1.46553834e-06, 6.48765782e-06, 4.94140582e-07],\n",
       "        [5.05338732e-08, 1.09282369e-06, 5.48659417e-06, 3.72307283e-07],\n",
       "        [1.40800583e-06, 7.12534872e-07, 1.73978681e-07, 2.22622129e-07]]),\n",
       " array([[2.26522746e-06, 2.09244221e-06, 5.13813055e-06, 6.81121454e-07]]),\n",
       " array([[ 0.00023584, -0.0003835 ,  0.0003879 ,  0.00029608],\n",
       "        [ 0.00023727, -0.00038574,  0.0003902 ,  0.00029782],\n",
       "        [ 0.00023602, -0.00038496,  0.00038881,  0.00029703],\n",
       "        [ 0.00023889, -0.00038382,  0.00039045,  0.00029704]]),\n",
       " array([[ 0.000471  , -0.00076802,  0.00077581,  0.00059262]]),\n",
       " array([[-0.1705999 , -0.04008685],\n",
       "        [-0.16895066, -0.03969746],\n",
       "        [-0.17035409, -0.04002706],\n",
       "        [-0.16959428, -0.03985005]]),\n",
       " array([[-0.33864654, -0.07937331]])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
